[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wavelet Score-Based Generative Models",
    "section": "",
    "text": "Welcome to the website for our research on wavelet score-based generative models for seismic inversion. This site presents our work on developing efficient and scalable posterior surrogates for seismic inversion using wavelet score-based generative models.\n\n\nSeismic inversion poses significant computational challenges due to its high dimensionality and non-unique solutions. We propose a novel method integrating the Wavelet Score-Based Generative Model (WSGM) with Simulation-Based Inference (SBI) to enable efficient posterior sampling for full-waveform inference.\nRead the full abstract →\n\n\n\n\nIntroduction of conditional WSGM for posterior sampling in seismic inversion\nA cascaded network architecture designed to reduce memory consumption\nComprehensive experiments on synthetic datasets demonstrating superior performance\nGeneration of uncertainty estimates that correlate well with errors\n\n\n\n\n\nEge Cirakman (Istanbul Technical University)\nHuseyin Tuna Erdinc (Georgia Institute of Technology)\nFelix J. Herrmann (Georgia Institute of Technology)"
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Wavelet Score-Based Generative Models",
    "section": "",
    "text": "Seismic inversion poses significant computational challenges due to its high dimensionality and non-unique solutions. We propose a novel method integrating the Wavelet Score-Based Generative Model (WSGM) with Simulation-Based Inference (SBI) to enable efficient posterior sampling for full-waveform inference.\nRead the full abstract →"
  },
  {
    "objectID": "index.html#key-contributions",
    "href": "index.html#key-contributions",
    "title": "Wavelet Score-Based Generative Models",
    "section": "",
    "text": "Introduction of conditional WSGM for posterior sampling in seismic inversion\nA cascaded network architecture designed to reduce memory consumption\nComprehensive experiments on synthetic datasets demonstrating superior performance\nGeneration of uncertainty estimates that correlate well with errors"
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "Wavelet Score-Based Generative Models",
    "section": "",
    "text": "Ege Cirakman (Istanbul Technical University)\nHuseyin Tuna Erdinc (Georgia Institute of Technology)\nFelix J. Herrmann (Georgia Institute of Technology)"
  },
  {
    "objectID": "abstract.html",
    "href": "abstract.html",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "",
    "text": "\\[\n\\def\\textsc#1{\\dosc#1\\csod}\n\\def\\dosc#1#2\\csod{{\\rm #1{\\small #2}}}\n\\]",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#seismic-imaging",
    "href": "abstract.html#seismic-imaging",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "Seismic imaging",
    "text": "Seismic imaging\nSeismic imaging aims to reconstruct a velocity model \\(\\mathbf{x} \\in \\mathbb{R}^n\\) from seismic observations \\(\\mathbf{y} \\in \\mathbb{R}^m\\) recorded at the surface, governed by the forward model \\(\\mathbf{y} = \\mathbf{\\mathcal{F}}(\\mathbf{x}) + \\boldsymbol{\\epsilon}\\), where \\(\\mathbf{\\mathcal{F}}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) is a nonlinear operator solving the wave equation and \\(\\boldsymbol{\\epsilon}\\) represents noise (Virieux and Operto 2009). The inverse problem is ill-posed, non-uniqueness (e.g., \\(\\mathbf{\\mathcal{F}}(\\mathbf{x}_1) \\approx \\mathbf{\\mathcal{F}}(\\mathbf{x}_2) \\approx \\mathbf{y}\\)) and computational expensive due to its high dimensionality. Traditional full-waveform inversion (FWI) minimizes \\(\\|\\mathbf{\\mathcal{F}}(\\mathbf{x}) - \\mathbf{y}\\|_2^2\\) misfit objective to estimate \\(\\mathbf{x}\\), but it provides only point estimates without systematic uncertainty quantification (Virieux and Operto 2009). In contrast, our study targets estimation of the posterior \\(p(\\mathbf{x} \\mid \\mathbf{y})\\) in the Bayesian inference setting using the WSGM with SBI.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#sbi-for-posterior-estimation",
    "href": "abstract.html#sbi-for-posterior-estimation",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "SBI for posterior estimation",
    "text": "SBI for posterior estimation\nSBI proposes to directly estimate posterior \\(p_{\\theta}(\\mathbf{x} \\mid \\mathbf{y})\\) using simulated data pairs \\(\\mathcal{D} = \\{ (\\mathbf{x}_i, \\mathbf{y}_i) \\}_{i=1}^{N}\\), where \\(\\mathbf{x}_i\\)’s are generated via the forward model, and train conditional generative models without explicit likelihood \\(p(\\mathbf{y} \\mid \\mathbf{x})\\) computation, which can be costly or physically impossible in many scientific settings (Cranmer, Brehmer, and Louppe 2020). A common generative model, normalizing flows can perform this task; yet, the inherent invertible structure may cause limitations in its performance (Rizzuti, Siahkoohi, and Herrmann 2024). In this work, we instead adopt a Conditional Score-Based Generative Model—specifically, WSGM—within the SBI framework, enabling efficient posterior estimation across multiple scales. Notably, in our formulation \\(\\mathbf{y}\\) represents RTM images, which serve as summary statistics extracted from seismic observational data (Deans and Verdon 2012; Yin, Orozco, and Herrmann 2024).",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#score-based-generative-models-sgms-and-wsgm",
    "href": "abstract.html#score-based-generative-models-sgms-and-wsgm",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "Score-based generative models (SGMs) and WSGM",
    "text": "Score-based generative models (SGMs) and WSGM\nSGMs learn the gradient of the log-density (score function) \\(\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})\\) using a neural network \\(s_{\\boldsymbol{\\theta}}(\\mathbf{x})\\), typically trained via a denoising score-matching objective (Y. Song et al. 2020). Sampling proceeds via Langevin dynamics (Hyvärinen 2005): \\(\\mathbf{x}_{t+1} = \\mathbf{x}_t + \\eta s_{\\boldsymbol{\\theta}}(\\mathbf{x}_t) + \\sqrt{2 \\eta} \\mathbf{n}_t\\), where \\(\\mathbf{n}_t \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) and \\(\\eta\\) is the step size. While SGMs have shown impressive results in image synthesis tasks (Ho, Jain, and Abbeel 2020), their application in scientific domains such as geophysics poses additional challenges. In these settings, score functions can be highly ill-conditioned due to long-range spatial correlations in the data, which result in poorly conditioned covariance structures. This makes both the training and sampling procedures significantly slower and more memory-intensive.\nWSGM addresses these challenges through a multi-scale decomposition. WSGM proposes to decompose data into scaling coefficients, \\(\\mathbf{x}_j = \\gamma_j^{-1} \\mathbf{G} \\mathbf{x}_{j-1}\\), and detail coefficients, \\(\\bar{\\mathbf{x}}_j = \\gamma_j^{-1} \\bar{\\mathbf{G}} \\mathbf{x}_{j-1}\\), using orthonormal wavelet filters \\(\\mathbf{G}\\) and \\(\\bar{\\mathbf{G}}\\) where \\(j\\) and \\(\\gamma_j\\) denote scale and scale dependent normalization, respectively. After completing the scale-wise decomposition, WSGM learns a separate score model for each scale. In other words, score estimation is performed through a hierarchical architecture, progressing from coarse to fine scales. Importantly, at each scale, the generation of detail coefficients is conditioned on the corresponding scaling coefficients. A key innovation in WSGM is the use of scale-specific normalization, where each scale is normalized based on its own mean and standard deviation. This results in faster whitening and accelerates the learning of scale-specific score functions. We argue that the wavelet-based scale decomposition in WSGM is particularly effective for seismic inversion problems, as velocity models naturally exhibit strong scale-dependent features and long-range spatial correlations.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#training-objective-and-conditional-wsgm",
    "href": "abstract.html#training-objective-and-conditional-wsgm",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "Training objective and conditional WSGM",
    "text": "Training objective and conditional WSGM\nTo enable posterior estimation in seismic inversion, we extend SGM and WSGM to learn the conditional score \\(\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x} \\mid \\mathbf{y})\\). For SGM, this involves training a network \\(s_{\\boldsymbol{\\theta}}(\\mathbf{x}, \\mathbf{y}, \\sigma(t))\\) to approximate the score via a denoising objective conditioned on \\(\\mathbf{y}\\) (Batzolis et al. 2021; C. Song and Alkhalifah 2024). Given paired data \\((\\mathbf{x}, \\mathbf{y})\\), the objective becomes:\n\\[\n\\widehat{\\boldsymbol{\\theta}}_{\\text{SGM}} = \\mathop{\\mathrm{argmin}\\,}\\limits_{\\boldsymbol{\\theta}}\\mathbb{E}_{\\mathbf{y},\\mathbf{x}, \\mathbf{n}} \\left\\| s_{\\boldsymbol{\\theta}}(\\mathbf{x} + \\mathbf{n}, \\mathbf{y}, \\sigma(t)) - \\mathbf{x} \\right\\|_2^2\n\\]\nwhere \\(\\mathbf{n} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma(t)^2 \\mathbf{I})\\) and \\(\\sigma(t)\\) follows a noise schedule (Karras et al. 2022).\nFor WSGM (Guth and Bruna 2022), the multi-scale structure enables hierarchical conditioning and modeling. The posterior density can be expressed by hierarchical factorization as follows:\n\\[\np(\\mathbf{x} \\mid \\mathbf{y}) = p(\\mathbf{x}_J \\mid \\mathbf{y}_J) \\prod_{j = 1}^{J} p(\\overline{\\mathbf{x}}_j \\mid \\mathbf{x}_j, \\overline{\\mathbf{y}}_j)\n\\]\nwhere \\(\\mathbf{x}_j\\) is the velocity approximation at scale \\(j\\), formed via normalized wavelet transform (WT) as \\(\\text{WT}(\\mathbf{x}_{j}) = (\\mathbf{x}_{j+1}, \\overline{\\mathbf{x}}_{j+1})\\) with \\(\\mathbf{x}_j\\) and \\(\\overline{\\mathbf{x}}_j\\) representing scaling and detail coefficients at scale \\(j\\) and \\(j=1\\) corresponding to the finest scale. We can reverse the process with the inverse wavelet transform (IWT) and make similar arguments for \\(\\mathbf{y}_j\\).\nWith this factorization, we have divided the learning process to different cascaded models. The learning at the coarsest scale (\\(j=J\\)) can be expressed with the objective of SGM. However, for finer scales the score network learns \\(s_{\\boldsymbol{\\theta}_j}(\\overline{\\mathbf{x}}_j, \\mathbf{x}_j, \\overline{\\mathbf{y}}_j,\\sigma(t))\\). The loss at scale \\(j\\) integrates these dependencies and the objective becomes:\n\\[\n\\widehat{\\boldsymbol{\\theta}}_{\\text{WSGM}} = \\mathop{\\mathrm{argmin}\\,}\\limits_{\\boldsymbol{\\theta}}\\mathbb{E}_{\\overline{\\mathbf{y}}_j,\\mathbf{x}_j,\\overline{\\mathbf{x}}_j,\\mathbf{n}} \\left\\| s_{\\boldsymbol{\\theta}}(\\overline{\\mathbf{x}}_j + \\mathbf{n}, \\mathbf{x}_j, \\overline{\\mathbf{y}}_j, \\sigma(t)) - \\overline{\\mathbf{x}}_j \\right\\|_2^2\n\\]\nPosterior sampling proceeds by solving the reverse-time SDE conditioned on unseen \\(\\mathbf{y}^{\\text{obs}}\\). For WSGM, this process occurs sequentially: the coarsest-scale velocity \\(\\mathbf{x}_J\\) is sampled first, followed by detail coefficients \\(\\overline{\\mathbf{x}}_J\\), conditioned on \\(\\mathbf{x}_J\\) and \\(\\overline{\\mathbf{y}}_J\\). Then inverse wavelet transform of aggregated scaling and detail coefficients are used to proceed with finer scale and this process is repeated up to the original scale of inputs.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#dataset-creation",
    "href": "abstract.html#dataset-creation",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "Dataset creation",
    "text": "Dataset creation\nTo assess the proposed methodology, we utilize a synthetic 3D Earth model derived from the Compass model as a representative of geological formations in the North Sea region (Group and CGG 2015). The training dataset pairs consisting of the 2D velocities sliced through the 3D synthetic model and reverse-time migration (RTM) pairs. The total number of training samples is 3000 and the computational grid/resolution is 256x256 with a spatial resolution of 6.25 m, each sample covering an area of 3.2km x 3.2km. Seismic wave data is generated with 16 sources and 256 receivers with a dominant frequency of 15 Hz and a recording duration of 1.8 seconds. To simulate real-world conditions, 10 dB SNR colored Gaussian noise is added to the shot records before migration. The migration process for RTM is preformed with a Gaussian severely smoothed 2D background model. Wave simulations and imaging are performed using the open-source package JUDI (Witte et al. 2019).",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  },
  {
    "objectID": "abstract.html#inference-results",
    "href": "abstract.html#inference-results",
    "title": "Efficient and scalable posterior surrogate for seismic inversion via wavelet score-based generative models",
    "section": "Inference results",
    "text": "Inference results\n\n\n\n\n\n\nFigure 1: RTM image used as conditioning input for posterior sampling\n\n\n\n\n\n\n\n\n\nFigure 2: Comparison of velocity models: Ground truth (left), SGM posterior sample (middle), and WSGM posterior sample (right)\n\n\n\n\n\n\n\n\n\nFigure 3: Uncertainty quantification: Variance maps for SGM (left) and WSGM (right) posterior samples\n\n\n\nWe evaluate our method by comparing posterior samples generated by WSGM against those from standard SGM, using the same conditioning RTM image (Figure 1). Both methods produce velocity models that capture the main geological structures present in the ground truth (Figure 2). However, WSGM achieves this with significantly reduced computational requirements: memory usage is approximately 50% lower, and sampling time is reduced by about 73% compared to SGM.\nThe variance maps (Figure 3) reveal that both methods correctly identify areas of high uncertainty, which correspond to regions where the RTM image provides limited information due to illumination issues or complex wave propagation. Notably, WSGM’s uncertainty estimates correlate well with actual prediction errors, suggesting that the multi-scale decomposition effectively captures the hierarchical nature of uncertainty in the velocity model.\nTo quantitatively assess performance, we compute the structural similarity index (SSIM) between posterior samples and ground truth, finding that WSGM (SSIM = 0.87 ± 0.03) performs comparably to SGM (SSIM = 0.89 ± 0.02). This slight difference in accuracy is outweighed by WSGM’s substantial computational advantages, especially for large-scale applications.\nFurthermore, WSGM’s hierarchical structure naturally enables multi-resolution inference, allowing practitioners to first examine coarse-scale features before progressively refining to higher resolutions. This capability is particularly valuable in exploration settings, where initial rapid assessments can guide subsequent, more detailed analyses.",
    "crumbs": [
      "Home",
      "Abstracts",
      "Wavelet Score-Based Generative Models"
    ]
  }
]